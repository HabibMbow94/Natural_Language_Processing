{"cells":[{"cell_type":"markdown","metadata":{"id":"MOX_k607uYnJ"},"source":["The goal of this lab is to implement a language identifier (LID).\n","\n","Our first model will be based on Naive Bayes."]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":648,"status":"ok","timestamp":1652258437550,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"EBeV8NPTuYnM"},"outputs":[],"source":["import io, sys, math, re\n","from collections import defaultdict"]},{"cell_type":"markdown","metadata":{"id":"Vdjb_CStuYnM"},"source":["The next function is used to load the data. Each line of the data consist of a label (corresponding to a language), followed by some text, written in that language. Here is an example of data:\n","\n","```__label__de Zur Namensdeutung gibt es mehrere Varianten.```\n"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1652258197096,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"__WsOuGiuYnN"},"outputs":[],"source":["def load_data(filename):\n","    fin = io.open(filename, 'r', encoding='utf-8')\n","    data = []\n","    for line in fin:\n","        tokens = line.split()\n","        data.append((tokens[0], tokens[1:]))\n","    return data"]},{"cell_type":"markdown","metadata":{"id":"UptLj38suYnN"},"source":["You can now try loading the first dataset `train1.txt` and look what examples look like."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1331,"status":"ok","timestamp":1652258441691,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"qBYfVAk7uYnN"},"outputs":[],"source":["data = load_data(\"train1.txt\")\n"]},{"cell_type":"markdown","metadata":{"id":"I6Yd7PkJuYnN"},"source":["Next, we will start implementing the Naive Bayes method. This technique is based on word counts, and we thus need to start by implementing a function to count the words and labels of our training set.\n","\n","`n_examples` is the total number of examples\n","\n","`n_words_per_label` is the total number of words for a given label\n","\n","`label_counts` is the number of times a given label appears in the training data\n","\n","`word_counts` is the number of times a word appears with a given label"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":452,"status":"ok","timestamp":1652260066398,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"wY_S3mRYuYnO"},"outputs":[],"source":["def count_words(data):\n","    n_examples = 0\n","    n_words_per_label = defaultdict(lambda: 0)\n","    label_counts = defaultdict(lambda: 0)\n","    word_counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n","\n","    for example in data:\n","      label, sentence = example\n","      ## FILL CODE\n","      n_examples+= 1\n","      label_counts[label]= label_counts[label] +1\n","\n","      for w in sentence:\n","        word_counts[label][w] +=1\n","        n_words_per_label[label] = n_words_per_label[label] +1\n","\n","\n","    return {'label_counts': label_counts, \n","            'word_counts': word_counts, \n","            'n_examples': n_examples, \n","            'n_words_per_label': n_words_per_label}"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1652260067683,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"N2EFolgZ0F6L"},"outputs":[],"source":["train_data = load_data(\"train1.txt\")\n","counts = count_words(train_data)"]},{"cell_type":"markdown","metadata":{"id":"yxzMVjCvuYnO"},"source":["Next, using the word and label counts from the previous function, we can implement the prediction function.\n","\n","Here, `mu` is a regularization parameter (Laplace smoothing), and `sentence` is the list of words corresponding to the test example."]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":309,"status":"ok","timestamp":1652260071867,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"NjwCUTsLakRl"},"outputs":[],"source":["def predict(sentence, mu, label_counts, word_counts, n_examples, n_words_per_label):\n","    best_label = None\n","    best_score = float('-inf')\n","\n","    for label in word_counts.keys():\n","      score = 0.0\n","      ## FILE CODE\n","      voc_size= len(word_counts[label])\n","\n","      for w in sentence:\n","        word_count_w= word_counts[label][w] + mu\n","        denominator= n_words_per_label[label] + voc_size*mu\n","\n","        # print(denominator)\n","\n","        score+= math.log(word_count_w/denominator)\n","\n","        if score > best_score:\n","          best_score=score\n","          best_label= label\n","    return best_label"]},{"cell_type":"markdown","metadata":{"id":"Bm6iosMLuYnP"},"source":["The next function will be used to evaluate the Naive Bayes model on a validation set. It computes the accuracy for a particular regularization parameter `mu`."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":448,"status":"ok","timestamp":1652260122620,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"3I_Ji6rlaqIj"},"outputs":[],"source":["def compute_accuracy(valid_data, mu, counts):\n","    accuracy = 0.0\n","    n = len(valid_data)\n","    for label, sentence in valid_data:\n","        ## FILL CODE\n","      lab_pred= predict(sentence, mu, **counts)\n","      \n","      if lab_pred == label:\n","        accuracy+=1\n","\n","     \n","    return 100*accuracy/n"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":813,"status":"ok","timestamp":1652220350842,"user":{"displayName":"Habib Mbow","userId":"02819842679184620741"},"user_tz":0},"id":"x01HzQBuuYnQ","outputId":"fe64e7a0-549a-4daa-8dab-f9d46f6bc178"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","** Naive Bayes **\n","\n","Validation accuracy: 69.700\n"]}],"source":["print(\"\")\n","print(\"** Naive Bayes **\")\n","print(\"\")\n","\n","mu = 1.0\n","train_data = load_data(\"train1.txt\")\n","valid_data = load_data(\"valid1.txt\")\n","counts = count_words(train_data)\n","\n","print(\"Validation accuracy: %.3f\" % compute_accuracy(valid_data, mu, counts))"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Habib_MBOW_naive_bayes.ipynb","provenance":[{"file_id":"1LN4bSp35ggZpXxPLHWUuKJm1coN96f49","timestamp":1652199201603}]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"7a46bd6e24c1f53fffd0c2fe37a3e93b2b8ebf08f8d9dc31c4646ffc9359c678"}}},"nbformat":4,"nbformat_minor":0}
